<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>딥러닝 모델을 이용한 이미지 분류 - 코드 설명</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            background-color: #f4f4f4;
            margin: 0;
            padding: 0;
        }
        header {
            background-color: #4CAF50;
            color: white;
            text-align: center;
            padding: 10px 0;
        }
        main {
            padding: 20px;
            margin: 20px;
            background-color: white;
            border-radius: 8px;
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background-color: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-size: 16px;
        }
        .code-section {
            margin-bottom: 20px;
        }
        .code-section p {
            font-size: 18px;
            margin-bottom: 10px;
        }
        footer {
            text-align: center;
            padding: 10px;
            background-color: #333;
            color: white;
        }
    </style>
</head>
<body>

<header>
    <h1>딥러닝 모델을 이용한 이미지 분류 코드 설명</h1>
</header>

<main>
    <section class="code-section">
        <h2>1. 라이브러리 임포트 및 설정</h2>
        <p>이 부분에서는 필요한 라이브러리들을 임포트하고, CUDA 설정 및 장치를 설정합니다.</p>
        <pre>
import os
import random
import torch
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from PIL import Image
from tqdm import tqdm
from google.colab import drive
        </pre>
        <p>각각의 라이브러리는 데이터 처리, 모델 학습 및 평가에 필요합니다.</p>
    </section>

    <section class="code-section">
        <h2>2. CUDA 설정 및 장치 확인</h2>
        <p>이 코드는 GPU 사용 여부를 확인하고, 필요한 CUDA 설정을 합니다.</p>
        <pre>
torch.use_deterministic_algorithms(False)  # 결정적 알고리즘 비활성화
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # CUDA에서 발생하는 비결정적 오류 해결

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        </pre>
        <p>CUDA 오류를 해결하고, GPU가 있는 경우 GPU를, 없으면 CPU를 사용하도록 설정합니다.</p>
    </section>

    <section class="code-section">
        <h2>3. 랜덤 시드 고정</h2>
        <p>모델 학습의 재현성을 위해 랜덤 시드를 고정합니다.</p>
        <pre>
random_seed = 999
random.seed(random_seed)
np.random.seed(random_seed)
torch.manual_seed(random_seed)
torch.cuda.manual_seed_all(random_seed)
        </pre>
        <p>학습 시 동일한 결과를 얻기 위해 시드를 고정합니다.</p>
    </section>

    <section class="code-section">
        <h2>4. Google Drive 마운트</h2>
        <p>Google Colab 환경에서 Google Drive를 마운트하여 데이터에 접근합니다.</p>
        <pre>
drive.mount('/content/drive')
        </pre>
        <p>Colab에서 Google Drive를 연결하여 파일을 쉽게 불러올 수 있습니다.</p>
    </section>

    <section class="code-section">
        <h2>5. 데이터셋 경로 설정</h2>
        <p>데이터 파일과 이미지 경로를 설정합니다.</p>
        <pre>
base_dir = "/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024"
train_csv_path = os.path.join(base_dir, "train.csv")
test_dir = os.path.join(base_dir, "Test")
train_images_dir = os.path.join(base_dir, 'Train')
        </pre>
        <p>학습용 이미지와 테스트 이미지가 저장된 경로를 설정합니다.</p>
    </section>

    <section class="code-section">
        <h2>6. CSV 파일 읽기 및 클래스 레이블 매핑</h2>
        <p>CSV 파일을 읽어와서 이미지의 레이블을 숫자로 변환합니다.</p>
        <pre>
train_df = pd.read_csv(train_csv_path)
train_df['label'] = train_df['label'].map({'editada': 0, 'real': 1})
        </pre>
        <p>레거시 레이블 'editada'는 0, 'real'은 1로 매핑됩니다.</p>
    </section>

    <section class="code-section">
        <h2>7. 커스텀 데이터셋 클래스 정의</h2>
        <p>PyTorch의 Dataset 클래스를 상속하여 커스텀 데이터셋 클래스를 정의합니다.</p>
        <pre>
class CustomDataset(Dataset):
    def __init__(self, dataframe, image_folder, transform=None):
        self.img_labels = dataframe
        self.image_folder = image_folder
        self.transform = transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_name = os.path.join(self.image_folder, self.img_labels.iloc[idx, 0])
        image = Image.open(img_name).convert('RGB')
        label = int(self.img_labels.iloc[idx, 1])

        if self.transform:
            image = self.transform(image)

        return image, label
        </pre>
        <p>이미지 경로와 레이블을 이용하여 데이터를 반환하는 커스텀 데이터셋을 정의합니다.</p>
    </section>

    <section class="code-section">
        <h2>8. 이미지 변환 정의</h2>
        <p>이미지를 모델에 맞게 변환하는 작업을 정의합니다.</p>
        <pre>
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
        </pre>
        <p>이미지를 224x224 크기로 리사이즈하고, 텐서로 변환 후 정규화합니다.</p>
    </section>

    <section class="code-section">
        <h2>9. 데이터셋 나누기 (학습/검증)</h2>
        <p>데이터셋을 학습용과 검증용으로 나눕니다.</p>
        <pre>
train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=random_seed)
        </pre>
        <p>전체 데이터를 80%는 학습용, 20%는 검증용으로 나눕니다.</p>
    </section>

    <section class="code-section">
        <h2>10. DataLoader 객체 생성</h2>
        <p>DataLoader를 사용해 배치 단위로 데이터를 로드합니다.</p>
        <pre>
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)
        </pre>
        <p>배치 크기는 32로 설정하고, 학습 데이터는 셔플하여 로드합니다.</p>
    </section>

    <section class="code-section">
        <h2>11. EfficientNet V2 모델 정의</h2>
        <p>EfficientNet V2 모델을 사용하여 분류기를 정의합니다.</p>
        <pre>
class EffnetModel(nn.Module):
    def __init__(self):
        super(EffnetModel, self).__init__()
        self.model = models.efficientnet_v2_s(weights='DEFAULT')
        self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, 2)

    def forward(self, x):
        return self.model(x)
        </pre>
        <p>EfficientNet V2를 기반으로 하여 마지막 분류층을 2개의 클래스에 맞게 수정합니다.</p>
    </section>

    <section class="code-section">
        <h2>12. 손실 함수 및 최적화 함수 정의</h2>
        <p>모델 학습을 위한 손실 함수와 최적화 알고리즘을 정의합니다.</p>
        <pre>
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(EFF_NET.parameters(), lr=1e-4)
        </pre>
        <p>CrossEntropyLoss를 사용하여 분류 문제를 해결하고, Adam 옵티마이저로 모델을 최적화합니다.</p>
    </section>

    <section class="code-section">
        <h2>13. 모델 학습</h2>
        <p>모델을 학습시키고, 매 epoch마다 손실 및 검증 정확도를 출력합니다.</p>
        <pre>
for epoch in range(num_epochs):
    EFF_NET.train()
    # training loop
    # validation loop
        </pre>
        <p>학습 및 검증 루프를 통해 모델을 개선하고 최적의 모델을 저장합니다.</p>
    </section>

    <section class="code-section">
        <h2>14. 테스트 데이터셋에 대한 예측</h2>
        <p>학습된 모델을 사용하여 테스트 데이터에 대해 예측을 수행합니다.</p>
        <pre>
test_images = sorted(os.listdir(test_dir))
test_data = []
# 예측
        </pre>
        <p>테스트 이미지를 처리하고 모델로 예측을 수행하여 결과를 저장합니다.</p>
    </section>

    <section class="code-section">
        <h2>15. 제출 파일 생성</h2>
        <p>예측 결과를 CSV 파일로 저장하여 제출 파일을 생성합니다.</p>
        <pre>
submission = pd.DataFrame(test_data, columns=["image", "label"])
submission.to_csv("/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024/submission.csv", index=False)
        </pre>
        <p>결과는 CSV 파일로 저장되어 쉽게 제출할 수 있습니다.</p>
    </section>
</main>

<footer>
    <p>&copy; 2024 딥러닝 코드 설명 블로그</p>
</footer>

</body>
</html>
