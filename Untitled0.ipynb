{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNVqV5ruahYbHEsb59JfN6z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dTxGZyVphVP2"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["!pip install torch torchvision pandas matplotlib\n"],"metadata":{"id":"-LXAOAzJhbE-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ljg_5HfUhcpN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","import torch\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, models, transforms\n","from PIL import Image\n","from tqdm import tqdm\n","from google.colab import drive\n","\n","# GPU 사용 여부 확인\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 랜덤 시드 고정\n","random_seed = 999\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed)\n","\n","# Google Drive 마운트\n","drive.mount('/content/drive')\n","\n","# 데이터셋 디렉토리 설정\n","base_dir = \"/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024\"\n","train_csv_path = os.path.join(base_dir, \"train.csv\")\n","test_dir = os.path.join(base_dir, \"Test\")\n","\n","# CSV 파일 읽기\n","train_df = pd.read_csv(train_csv_path)\n","\n","# 클래스 레이블이 문자열로 되어 있으므로, 이를 숫자로 매핑\n","train_df['label'] = train_df['label'].map({'editada': 0, 'real': 1})\n","\n","# 이미지 경로 및 레이블 정의\n","image_folder = os.path.join(base_dir, 'Train')\n","\n","# 이미지 데이터셋 클래스 정의\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, image_folder, transform=None):\n","        self.img_labels = dataframe\n","        self.image_folder = image_folder\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.image_folder, self.img_labels.iloc[idx, 0])  # 이미지 경로\n","        image = Image.open(img_name).convert('RGB')  # 이미지 열기\n","        label = int(self.img_labels.iloc[idx, 1])  # 레이블\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# 데이터 변환 정의\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# 학습 및 검증 데이터셋 분리\n","train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=random_seed)\n","\n","# CustomDataset으로 데이터셋 객체 생성\n","train_dataset = CustomDataset(train_df, image_folder, transform=transform)\n","val_dataset = CustomDataset(val_df, image_folder, transform=transform)\n","\n","# DataLoader 객체 생성\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","# EfficientNet 모델 정의\n","class EffnetModel(nn.Module):\n","    def __init__(self):\n","        super(EffnetModel, self).__init__()\n","        self.model = models.efficientnet_v2_s(pretrained=True)  # EfficientNet V2 모델\n","        self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, 2)  # 출력 클래스 수를 2로 설정\n","\n","    def forward(self, x):\n","        return self.model(x)  # 로짓을 반환\n","\n","# 모델 초기화 및 GPU 설정\n","EFF_NET = EffnetModel().to(device)\n","\n","# 손실 함수와 최적화 함수 정의\n","criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss는 로짓을 기대\n","optimizer = optim.Adam(EFF_NET.parameters(), lr=1e-4)\n","\n","# 모델 학습\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    EFF_NET.train()\n","    running_loss = 0.0\n","    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # 모델 예측\n","        outputs = EFF_NET(inputs)  # 로짓을 반환\n","        loss = criterion(outputs, labels)  # CrossEntropyLoss는 로짓을 기대\n","        optimizer.zero_grad()  # 기울기 초기화\n","        loss.backward()  # 역전파\n","        optimizer.step()  # 최적화\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n","\n","    # 검증 데이터셋에서 성능 평가\n","    EFF_NET.eval()  # 평가 모드\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = EFF_NET(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")\n","\n","# 테스트 데이터셋에 대해 예측 수행\n","# test_loader 준비 (여기서는 'Test' 폴더에 이미지가 있다고 가정)\n","test_images = sorted(os.listdir(test_dir))  # 이미지 파일 목록\n","test_data = []\n","\n","for img_name in test_images:\n","    img_path = os.path.join(test_dir, img_name)\n","    img = Image.open(img_path).convert('RGB')\n","    img = transform(img).unsqueeze(0).to(device)  # 배치 차원 추가\n","\n","    EFF_NET.eval()\n","    with torch.no_grad():\n","        output = EFF_NET(img)\n","        _, predicted = torch.max(output.data, 1)\n","        test_data.append((img_name, predicted.item()))\n","\n","# 제출 파일 준비\n","submission = pd.DataFrame(test_data, columns=[\"image\", \"label\"])\n","submission[\"label\"] = submission[\"label\"].map({0: \"editada\", 1: \"real\"})  # 숫자를 원래 클래스 이름으로 변환\n","submission.to_csv(\"/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024/submission.csv\", index=False)\n","\n","print(\"Submission file created at '/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024/submission.csv'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tllFynqPhd-V","executionInfo":{"status":"ok","timestamp":1732677331569,"user_tz":-540,"elapsed":514669,"user":{"displayName":"현우","userId":"13721909872316796663"}},"outputId":"c3c15be7-73d5-487b-c640-00ad499d5566"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n","100%|██████████| 82.7M/82.7M [00:01<00:00, 72.7MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.7158\n","Validation Accuracy: 54.86%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Loss: 0.5960\n","Validation Accuracy: 52.78%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Loss: 0.4585\n","Validation Accuracy: 59.03%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Loss: 0.2596\n","Validation Accuracy: 67.36%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Loss: 0.1371\n","Validation Accuracy: 69.44%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Loss: 0.1170\n","Validation Accuracy: 68.06%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Loss: 0.1150\n","Validation Accuracy: 77.08%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Loss: 0.0880\n","Validation Accuracy: 70.83%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Loss: 0.0634\n","Validation Accuracy: 77.78%\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Loss: 0.0301\n","Validation Accuracy: 79.17%\n","Submission file created at '/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024/submission.csv'\n"]}]},{"cell_type":"code","source":["import os\n","import random\n","import torch\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","from PIL import Image\n","from tqdm import tqdm\n","from google.colab import drive\n","\n","# CUDA 설정 관련 오류 처리\n","torch.use_deterministic_algorithms(False)  # 결정적 알고리즘 비활성화\n","os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # CUDA에서 발생하는 비결정적 오류 해결\n","\n","# GPU 사용 여부 확인\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 랜덤 시드 고정\n","random_seed = 999\n","random.seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed)\n","\n","# Google Drive 마운트\n","drive.mount('/content/drive')\n","\n","# 데이터셋 디렉토리 설정\n","base_dir = \"/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024\"\n","train_csv_path = os.path.join(base_dir, \"train.csv\")\n","test_dir = os.path.join(base_dir, \"Test\")\n","train_images_dir = os.path.join(base_dir, 'Train')\n","\n","# CSV 파일 읽기\n","train_df = pd.read_csv(train_csv_path)\n","\n","# 클래스 레이블을 0과 1로 매핑\n","train_df['label'] = train_df['label'].map({'editada': 0, 'real': 1})\n","\n","# 이미지 데이터셋 클래스 정의\n","class CustomDataset(Dataset):\n","    def __init__(self, dataframe, image_folder, transform=None):\n","        self.img_labels = dataframe\n","        self.image_folder = image_folder\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.image_folder, self.img_labels.iloc[idx, 0])  # 이미지 경로\n","        image = Image.open(img_name).convert('RGB')  # 이미지 열기\n","        label = int(self.img_labels.iloc[idx, 1])  # 레이블\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# 데이터 변환 정의\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# 학습 및 검증 데이터셋 분리\n","train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=random_seed)\n","\n","# CustomDataset으로 데이터셋 객체 생성\n","train_dataset = CustomDataset(train_df, train_images_dir, transform=transform)\n","val_dataset = CustomDataset(val_df, train_images_dir, transform=transform)\n","\n","# DataLoader 객체 생성\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n","\n","# EfficientNet 모델 정의\n","class EffnetModel(nn.Module):\n","    def __init__(self):\n","        super(EffnetModel, self).__init__()\n","        self.model = models.efficientnet_v2_s(weights='DEFAULT')  # EfficientNet V2 모델\n","        self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, 2)  # 출력 클래스 수를 2로 설정\n","\n","    def forward(self, x):\n","        return self.model(x)  # 로짓을 반환\n","\n","# 모델 초기화 및 GPU 설정\n","EFF_NET = EffnetModel().to(device)\n","\n","# 손실 함수와 최적화 함수 정의\n","criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss는 로짓을 기대\n","optimizer = optim.Adam(EFF_NET.parameters(), lr=1e-4)\n","\n","# 모델 학습\n","num_epochs = 10\n","best_val_accuracy = 0.0\n","for epoch in range(num_epochs):\n","    EFF_NET.train()\n","    running_loss = 0.0\n","    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # 모델 예측\n","        outputs = EFF_NET(inputs)  # 로짓을 반환\n","        loss = criterion(outputs, labels)  # CrossEntropyLoss는 로짓을 기대\n","        optimizer.zero_grad()  # 기울기 초기화\n","        loss.backward()  # 역전파\n","        optimizer.step()  # 최적화\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n","\n","    # 검증 데이터셋에서 성능 평가\n","    EFF_NET.eval()  # 평가 모드\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = EFF_NET(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    val_accuracy = 100 * correct / total\n","    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n","\n","    # 최고의 모델 저장 (검증 정확도가 개선될 때마다)\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        torch.save(EFF_NET.state_dict(), \"/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024/best_model.pth\")\n","        print(\"Best model saved!\")\n","\n","# 테스트 데이터셋에 대해 예측 수행\n","test_images = sorted(os.listdir(test_dir))  # 이미지 파일 목록\n","test_data = []\n","\n","for img_name in test_images:\n","    img_path = os.path.join(test_dir, img_name)\n","    img = Image.open(img_path).convert('RGB')\n","    img = transform(img).unsqueeze(0).to(device)  # 배치 차원 추가\n","\n","    EFF_NET.eval()\n","    with torch.no_grad():\n","        output = EFF_NET(img)\n","        _, predicted = torch.max(output.data, 1)\n","        test_data.append((img_name, predicted.item()))  # 0과 1로 된 label 저장\n","\n","# 제출 파일 준비\n","submission = pd.DataFrame(test_data, columns=[\"image\", \"label\"])\n","submission.to_csv(\"/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024/submission.csv\", index=False)\n","\n","print(\"Submission file created at '/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024/submission.csv'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bH--Wg06oinE","executionInfo":{"status":"ok","timestamp":1732678230541,"user_tz":-540,"elapsed":265782,"user":{"displayName":"현우","userId":"13721909872316796663"}},"outputId":"f12d675c-0754-4450-8be9-dcf98af17563"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.7158\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 54.86%\n","Best model saved!\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Loss: 0.5960\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 52.78%\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Loss: 0.4585\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 59.03%\n","Best model saved!\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Loss: 0.2595\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 66.67%\n","Best model saved!\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Loss: 0.1370\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 70.14%\n","Best model saved!\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Loss: 0.1166\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 67.36%\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Loss: 0.1166\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 75.00%\n","Best model saved!\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Loss: 0.0994\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 75.69%\n","Best model saved!\n"]},{"output_type":"stream","name":"stderr","text":["                                                           "]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Loss: 0.0622\n"]},{"output_type":"stream","name":"stderr","text":["\r"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 79.17%\n","Best model saved!\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Loss: 0.0396\n","Validation Accuracy: 77.08%\n","Submission file created at '/content/drive/MyDrive/cidaut-ai-fake-scene-classification-2024/submission.csv'\n"]}]}]}